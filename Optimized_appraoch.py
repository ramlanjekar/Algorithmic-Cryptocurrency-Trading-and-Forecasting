# -*- coding: utf-8 -*-
"""Copy of 01_Strategy_Optimization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h3brL0Nl9WTckOglPZNg-e2oMcnvz_4A

### 1 - Import test data
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install pandas_ta

import pandas as pd
import pandas_ta as ta


df = pd.read_csv("/content/drive/MyDrive/btc_1h.csv")
df.columns = [col.capitalize() for col in df.columns]

df=df[df.High!=df.Low]
df.set_index("Datetime", inplace=True)

df["EMA"]=ta.ema(df.Close, length=30)
df['RSI']=ta.rsi(df.Close, length=10)
my_bbands = ta.bbands(df.Close, length=15, std=1.5)
df['ATR']=ta.atr(df.High, df.Low, df.Close, length=7)
df=df.join(my_bbands)
df

def ema_signal(df, current_candle, backcandles):
    df_slice = df.reset_index().copy()

    df_slice = df_slice.loc[current_candle-backcandles:current_candle, ["Open", "Close", "EMA"]]
    dnt = 0 if (df_slice[["Open", "Close"]].max(axis=1) >= df_slice["EMA"]).any() else 1
    upt = 0 if (df_slice[["Open", "Close"]].min(axis=1) <= df_slice["EMA"]).any() else 1

    if upt==1 and dnt==1:
        return 3
    elif upt==1:
        return 2
    elif dnt==1:
        return 1
    else:
        return 0


ema_signal(df, 1313, 5)
from tqdm import tqdm
tqdm.pandas()
df.reset_index(inplace=True)
df['EMASignal'] = df.progress_apply(lambda row: ema_signal(df, row.name, 5) if row.name >= 20 else 0, axis=1)

def total_signal(df, current_candle, backcandles):
    if (df['EMASignal'][current_candle]==2
        and df.Close[current_candle]<=df['BBL_15_1.5'][current_candle]
        #and df.RSI[current_candle]<60
        ):
            return 2
    if (df['EMASignal'][current_candle]==1
        and df.Close[current_candle]>=df['BBU_15_1.5'][current_candle]
        #and df.RSI[current_candle]>40
        ):

            return 1
    return 0

df['TotalSignal'] = df.progress_apply(lambda row: total_signal(df, row.name, 7), axis=1)
df['EMASignal']=df['EMASignal']

df.head()

import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime
st=100
dfpl = df[st:st+350]
#dfpl.reset_index(inplace=True)
fig = go.Figure(data=[go.Candlestick(x=dfpl.index,
                open=dfpl['Open'],
                high=dfpl['High'],
                low=dfpl['Low'],
                close=dfpl['Close']),

                go.Scatter(x=dfpl.index, y=dfpl['BBL_15_1.5'],
                           line=dict(color='green', width=1),
                           name="BBL"),
                go.Scatter(x=dfpl.index, y=dfpl['BBU_15_1.5'],
                           line=dict(color='green', width=1),
                           name="BBU"),
                go.Scatter(x=dfpl.index, y=dfpl['EMA'],
                           line=dict(color='black', width=1),
                           name="EMA")           ])

fig.show()

def SIGNAL():
    return df.TotalSignal

!pip install backtesting

from backtesting import Strategy
from backtesting import Backtest

class MyStrat(Strategy):
    mysize = 0.99
    slcoef = 1.2 #1.3
    TPSLRatio = 2 # 1.8
    def init(self):
        super().init()
        self.signal1 = self.I(SIGNAL)

    def next(self):
        super().next()
        slatr = self.slcoef*self.data.ATR[-1]
        TPSLRatio = self.TPSLRatio

        if len(self.trades)>0:
            if self.trades[-1].is_long and self.data.RSI[-1]>=90:
                self.trades[-1].close()
            elif self.trades[-1].is_short and self.data.RSI[-1]<=10:
                self.trades[-1].close()

        if self.signal1==2 and len(self.trades)==0:
            sl1 = self.data.Close[-1] - slatr
            tp1 = self.data.Close[-1] + slatr*TPSLRatio
            self.buy(sl=sl1, tp=tp1, size=self.mysize)

        elif self.signal1==1 and len(self.trades)==0:
            sl1 = self.data.Close[-1] + slatr
            tp1 = self.data.Close[-1] - slatr*TPSLRatio
            self.sell(sl=sl1, tp=tp1, size=self.mysize)

bt = Backtest(df, MyStrat, cash=250, margin=1/30, commission=0.00)
stats, heatmap = bt.optimize(slcoef=[i/10 for i in range(10, 21)],
                    TPSLRatio=[i/10 for i in range(10, 21)],
                    maximize='Return [%]', max_tries=300,
                        random_state=0,
                        return_heatmap=True)
stats

stats["_strategy"]

bt.run()
bt.plot()

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Convert multiindex series to dataframe
heatmap_df = heatmap.unstack()
plt.figure(figsize=(10, 8))
sns.heatmap(heatmap_df, annot=True, cmap='viridis', fmt='.0f')
plt.show()

df.head()

import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Assuming you have your data and target labels ready
# For example purposes, let's assume data is in variable 'X' and labels in variable 'y'
X = df.drop('TotalSignal', axis=1).values  # Extracting features except 'TotalSignal'
y = df['TotalSignal'].values

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Feature scaling (assuming X contains numerical features)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reshaping data to fit the LSTM input shape (assuming a time series format)
time_steps = 10  # Define the number of time steps for the LSTM
num_features = X_train_scaled.shape[1]  # Number of features in the input data

def prepare_data_for_lstm(data, time_steps):
    data_lstm = []
    for i in range(len(data) - time_steps):
        data_lstm.append(data[i:i+time_steps])
    return np.array(data_lstm)

X_train_lstm = prepare_data_for_lstm(X_train_scaled, time_steps)
X_test_lstm = prepare_data_for_lstm(X_test_scaled, time_steps)

# Constructing the LSTM model
model = tf.keras.Sequential([
    tf.keras.layers.LSTM(units=64, input_shape=(time_steps, num_features), return_sequences=True),
    tf.keras.layers.LSTM(units=32),
    tf.keras.layers.Dense(units=1)  # Output layer for regression task
])

# Compiling the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse'])

# Training the model
model.fit(X_train_lstm, y_train[time_steps:], epochs=10, batch_size=32, validation_split=0.1)

# Evaluating the model on test data
loss, mse = model.evaluate(X_test_lstm, y_test[time_steps:])
print(f'Test Loss: {loss}, Test MSE: {mse}')

# Making predictions
predictions = model.predict(X_test_lstm)

# Further analysis or utilization of predictions

print(predictions[:5])
